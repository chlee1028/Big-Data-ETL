{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import *\n",
    "from pyspark.sql import * #SparkSession, Row\n",
    "from pyspark.sql.functions import * #udf, concat, col, lit, ltrim, rtrim\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "global applicationName\n",
    "\n",
    "applicationName = \"testspark\"\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(applicationName)\n",
    "    .enableHiveSupport()\n",
    "    .config(\"hive.exec.dynamic.partition\", \"true\")\n",
    "    .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from myETLcode import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('house_prices.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------------------+------------------+--------------------+----------+-----------+-------------+--------+\n",
      "|             address|           amenities|     lat|                link|               lon|                name|     price|prize_range|         size|  tenure|\n",
      "+--------------------+--------------------+--------+--------------------+------------------+--------------------+----------+-----------+-------------+--------+\n",
      "|Jalan Cheras Inta...|3 Bedroom(s),2 Ba...|3.072998|https://www.iprop...|        101.774192|Cheras Intan, Cheras|RM 265,000|        Low|  750 sq. ft.|Freehold|\n",
      "|Jalan 6/95B, Tama...|3 Bedroom(s),2 Ba...| 3.10169|https://www.iprop...|101.75050999999999|Ketumbar Heights,...|RM 295,000|        Low|  755 sq. ft.|Freehold|\n",
      "|Mont Kiara, KL, K...|4+1 Bedroom(s),5 ...|     0.0|https://www.iprop...|               0.0|10 Mont Kiara @ M...| RM 10,000|        Low|3,668 sq. ft.|Freehold|\n",
      "|Jalan Langkawi, S...|3 Bedroom(s),2 Ba...|3.200666|https://www.iprop...|        101.708336|Teratai Mewah Apa...|RM 215,000|        Low|  653 sq. ft.|Freehold|\n",
      "|Persiaran Meranti...|3 Bedroom(s),2 Ba...|3.181858|https://www.iprop...|        101.611623|Sd Apartments, Ba...|RM 280,000|        Low|  811 sq. ft.|Freehold|\n",
      "+--------------------+--------------------+--------+--------------------+------------------+--------------------+----------+-----------+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert datatype of the prices \n",
    "- regexp_extract( col, regex_expression, index)     : extract *265,000* from *RM 265,000*\n",
    "- regexp_replace( col, regex_expression, replacing) : replace '*,*' with space\n",
    "- cast biginteger type to the number  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('prices', regexp_extract(col('price'),'RM (.+)',1))\\\n",
    "        .withColumn('prices', regexp_replace(col('prices'),',',''))\\\n",
    "        .withColumn('prices', col('prices').cast('bigint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     price|prices|\n",
      "+----------+------+\n",
      "|RM 265,000|265000|\n",
      "|RM 295,000|295000|\n",
      "| RM 10,000| 10000|\n",
      "+----------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('price','prices').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('lat', round('lat',3))\\\n",
    "       .withColumn('lon',round('lon',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple data profile on selected columns (only applies to small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prof = data_profile(df_my.select('House Name','amenities','prices'), spark.sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+-----+------------------+-----------------+-----+------+----+\n",
      "|    column|datatype|dist len|count|              mean|             s.d.|  min|   max|null|\n",
      "+----------+--------+--------+-----+------------------+-----------------+-----+------+----+\n",
      "|    prices|  bigint|      76|  239|312650.44351464434|53912.15545023094|10000|380000|   0|\n",
      "| amenities|  string|      32|  239|                  |                 |     |      |   0|\n",
      "|House Name|  string|     145|  239|                  |                 |     |      |   0|\n",
      "+----------+--------+--------+-----+------------------+-----------------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prof.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found that when massive ETL's involved, there are a lot of work needed to write the spark codes to perform transformation. To make my job easy, I wrote functions and wrap up spark original methods.\n",
    "The below will demo the difference between using spark original methods and the wrapped up methods.\n",
    "\n",
    "- `df_sp` used standard spark methods\n",
    "- `df_my` used my library methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming \n",
    "\n",
    "```\n",
    "rename_col(df,rename_map):\n",
    "```\n",
    "Rename the columns according to the renaming in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address',\n",
       " 'amenities',\n",
       " 'latitude',\n",
       " 'link',\n",
       " 'longitude',\n",
       " 'House Name',\n",
       " 'price',\n",
       " 'prize_range',\n",
       " 'size',\n",
       " 'tenure',\n",
       " 'prices']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp = df.withColumnRenamed('lat','latitude')\\\n",
    "          .withColumnRenamed('lon','longitude')\\\n",
    "          .withColumnRenamed('name','House Name')\n",
    "        \n",
    "df_sp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address',\n",
       " 'amenities',\n",
       " 'lat',\n",
       " 'link',\n",
       " 'lon',\n",
       " 'name',\n",
       " 'price',\n",
       " 'prize_range',\n",
       " 'size',\n",
       " 'tenure',\n",
       " 'prices']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my = rename_col(df, {'lat' :'latitude',\\\n",
    "                        'lon' :'longitude',\\\n",
    "                        'name':'House Name'})\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns\n",
    "```python\n",
    "    iter_drop(df, drop_cols)\n",
    "```\n",
    "Drop columns in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amenities',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'House Name',\n",
       " 'prize_range',\n",
       " 'size',\n",
       " 'prices']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp = df_sp.drop('price','tenure','link','address')\n",
    "df_sp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amenities',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'House Name',\n",
       " 'prize_range',\n",
       " 'size',\n",
       " 'prices',\n",
       " 'price_category']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['price','tenure','link','address']\n",
    "df_my = iter_drop(df_my, drop_cols)\n",
    "df_my.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If-Else\n",
    "```python\n",
    "recursive_cond(df, conditions,NA ='NA'):\n",
    "```\n",
    "alternative for when().otherwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sp = df_sp.withColumn('price_category', \\\n",
    "                                when((col('prices')>=200000)&(col('prices')< 250000),'200k - 250k')\\\n",
    "                     .otherwise(when((col('prices')>=250000)&(col('prices')< 300000),'250k - 300k')\\\n",
    "                     .otherwise(when((col('prices')>=300000)&(col('prices')< 350000),'300k - 350k')\\\n",
    "                     .otherwise(when((col('prices')>=350000)&(col('prices')< 400000),'350k - 400k')\\\n",
    "                     .otherwise('Others')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|price_category|\n",
      "+--------------+\n",
      "|   300k - 350k|\n",
      "|        Others|\n",
      "|   350k - 400k|\n",
      "|   200k - 250k|\n",
      "|   250k - 300k|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp.select('price_category').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conditions = [(lambda df: (df['prices']>=200000) & (df['prices']<250000) ,'200k - 250k'),\n",
    "              (lambda df: (df['prices']>=250000) & (df['prices']<300000) ,'250k - 300k'),\n",
    "              (lambda df: (df['prices']>=300000) & (df['prices']<350000) ,'300k - 350k'),\n",
    "              (lambda df: (df['prices']>=350000) & (df['prices']<400000) ,'350k - 400k')]\n",
    "\n",
    "df_my = df_my.withColumn('price_category', recursive_cond(df_my, conditions, 'Others'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|price_category|\n",
      "+--------------+\n",
      "|   300k - 350k|\n",
      "|        Others|\n",
      "|   350k - 400k|\n",
      "|   200k - 250k|\n",
      "|   250k - 300k|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_my.select('price_category').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "```python\n",
    "aggregation(df, group_col, agg_cols)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+---------+--------------+\n",
      "|prize_range|no_of_house|min_price|max_price|price_category|\n",
      "+-----------+-----------+---------+---------+--------------+\n",
      "|       High|        151|   300000|   380000|             2|\n",
      "|        Low|         88|    10000|   300000|             4|\n",
      "+-----------+-----------+---------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp_agg = df_sp.groupBy('prize_range')\\\n",
    "                 .agg(count('House Name').alias('no_of_house'),\n",
    "                      min('prices').alias('min_price'),\n",
    "                      max('prices').alias('max_price'),\n",
    "                      countDistinct('price_category').alias('price_category'))\n",
    "df_sp_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+--------------+-----------+\n",
      "|prize_range|max_price|min_price|price_category|no_of_house|\n",
      "+-----------+---------+---------+--------------+-----------+\n",
      "|       High|   380000|   300000|             2|        151|\n",
      "|        Low|   300000|    10000|             4|         88|\n",
      "+-----------+---------+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_my_agg = aggregation(df_my, 'prize_range', {'House Name'    :{'no_of_house':'count'},\n",
    "                                               'prices'        :{'min_price'  :'min',\n",
    "                                                                 'max_price'  :'max'},\n",
    "                                               'price_category':'countDistinct'})\n",
    "df_my_agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining\n",
    "\n",
    "```python\n",
    "joining(x,df1,df2,how,drop)\n",
    "\n",
    "how: left, right, inner\n",
    "drop: True, False\n",
    "```\n",
    "\n",
    "extra methods:\n",
    "- `select_join(select_columns, rename_column_dict)`\n",
    "- `join_alias(join_on_col_dict, rename_column_dict)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_join_results(df):\n",
    "    print('Columns:')\n",
    "    print(','.join(df.columns))\n",
    "    print('\\nTable:')\n",
    "    df.select('House Name','price_category','prize_range','drill_cate').sort('House Name').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an anonymous dataframe for joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_to_join = spark.createDataFrame([['Low','200k - 250k','Cheap' ,'Extra1'],\\\n",
    "                                    ['Low','250k - 300k','Middle Low','Extra2'],\n",
    "                                    ['Low','300k - 350k','Middle','Extra3'],\n",
    "                                    ['High','350k - 400k','High','Extra4']], \\\n",
    "                                    schema=['prize_range','category','drill','UnwantCol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+---------+\n",
      "|prize_range|   category|     drill|UnwantCol|\n",
      "+-----------+-----------+----------+---------+\n",
      "|        Low|200k - 250k|     Cheap|   Extra1|\n",
      "|        Low|250k - 300k|Middle Low|   Extra2|\n",
      "|        Low|300k - 350k|    Middle|   Extra3|\n",
      "|       High|350k - 400k|      High|   Extra4|\n",
      "+-----------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_to_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the two dataframe on \n",
    "\n",
    "\n",
    "df            | df_to_join    \n",
    "------------- |--------------\n",
    "prize_range   | range        \n",
    "price_category| category     \n",
    "\n",
    "drop away `category` only after joining then rename `drill` --> `drill_cate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "amenities,latitude,longitude,House Name,prize_range,size,prices,price_category,drill_cate\n",
      "\n",
      "Table:\n",
      "+--------------------+--------------+-----------+----------+\n",
      "|          House Name|price_category|prize_range|drill_cate|\n",
      "+--------------------+--------------+-----------+----------+\n",
      "|10 Mont Kiara @ M...|        Others|        Low|      null|\n",
      "|Akasia Apartments...|   250k - 300k|        Low|Middle Low|\n",
      "|Akasia Apartments...|   300k - 350k|       High|      null|\n",
      "|Alam Idaman, Shah...|   350k - 400k|       High|      High|\n",
      "|Alam Sanjung, Sub...|        Others|        Low|      null|\n",
      "|Alam Sanjung, Sub...|        Others|        Low|      null|\n",
      "|    Aman Dua, Kepong|   250k - 300k|        Low|Middle Low|\n",
      "|    Aman Dua, Kepong|   250k - 300k|        Low|Middle Low|\n",
      "|Aman Puri Apartme...|   250k - 300k|        Low|Middle Low|\n",
      "|Amara Boulevard A...|   250k - 300k|        Low|Middle Low|\n",
      "+--------------------+--------------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp_join = df_sp.join(df_to_join.select('prize_range','category','drill'), \\\n",
    "                        on=[df_sp['prize_range']    == df_to_join['prize_range'],\n",
    "                            df_sp['price_category'] == df_to_join['category']], \\\n",
    "                        how='left')\\\n",
    "                  .drop(df_to_join['prize_range']).drop('category')\\\n",
    "                  .withColumnRenamed('drill','drill_cate')\n",
    "\n",
    "show_join_results(df_sp_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "amenities,latitude,longitude,House Name,prize_range,size,prices,price_category,drill_cate\n",
      "\n",
      "Table:\n",
      "+--------------------+--------------+-----------+----------+\n",
      "|          House Name|price_category|prize_range|drill_cate|\n",
      "+--------------------+--------------+-----------+----------+\n",
      "|10 Mont Kiara @ M...|        Others|        Low|      null|\n",
      "|Akasia Apartments...|   250k - 300k|        Low|Middle Low|\n",
      "|Akasia Apartments...|   300k - 350k|       High|      null|\n",
      "|Alam Idaman, Shah...|   350k - 400k|       High|      High|\n",
      "|Alam Sanjung, Sub...|        Others|        Low|      null|\n",
      "|Alam Sanjung, Sub...|        Others|        Low|      null|\n",
      "|    Aman Dua, Kepong|   250k - 300k|        Low|Middle Low|\n",
      "|    Aman Dua, Kepong|   250k - 300k|        Low|Middle Low|\n",
      "|Aman Puri Apartme...|   250k - 300k|        Low|Middle Low|\n",
      "|Amara Boulevard A...|   250k - 300k|        Low|Middle Low|\n",
      "+--------------------+--------------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_my_join1 = joining(df1 = df_my, \n",
    "                      df2 = df_to_join.select('prize_range','category','drill'), \n",
    "                       x = {'prize_range':'prize_range',\n",
    "                           'price_category':'category'})\n",
    "\n",
    "df_my_join1 = rename_col(df_my_join1, {'drill':'drill_cate'})\n",
    "\n",
    "show_join_results(df_my_join1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "amenities,latitude,longitude,House Name,prize_range,size,prices,price_category,drill_cate,RANGE_RENAMED,category\n",
      "\n",
      "Table:\n",
      "+--------------------+--------------+-----------+----------+\n",
      "|          House Name|price_category|prize_range|drill_cate|\n",
      "+--------------------+--------------+-----------+----------+\n",
      "|10 Mont Kiara @ M...|        Others|        Low|      null|\n",
      "|Akasia Apartments...|   250k - 300k|        Low|Middle Low|\n",
      "|Akasia Apartments...|   300k - 350k|       High|      null|\n",
      "|Alam Idaman, Shah...|   350k - 400k|       High|      High|\n",
      "|Alam Sanjung, Sub...|        Others|        Low|      null|\n",
      "|Alam Sanjung, Sub...|        Others|        Low|      null|\n",
      "|    Aman Dua, Kepong|   250k - 300k|        Low|Middle Low|\n",
      "|    Aman Dua, Kepong|   250k - 300k|        Low|Middle Low|\n",
      "|Aman Puri Apartme...|   250k - 300k|        Low|Middle Low|\n",
      "|Amara Boulevard A...|   250k - 300k|        Low|Middle Low|\n",
      "+--------------------+--------------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J_option = {}\n",
    "J_option['sel'] = ['prize_range','category','drill']\n",
    "J_option['rj'] = {'drill':'drill_cate',\n",
    "                 'prize_range':'RANGE_RENAMED'}\n",
    "J_option['jo'] = {'prize_range':'prize_range',\n",
    "                  'price_category':'category'}\n",
    "\n",
    "df_my_join2 = joining(df1 = df_my, \n",
    "                      df2 = df_to_join.select(*select_join(**J_option)), \n",
    "                      x = join_alias(**J_option),\n",
    "                      drop=False)\n",
    "\n",
    "show_join_results(df_my_join2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
